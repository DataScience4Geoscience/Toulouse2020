{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to scikit-learn\n",
    "[Scikit-learn](http://scikit-learn.org/stable/index.html) provides a set of machine learning tools to infer and predict properties of data. It is a scientific toolbox built around Scipy, dedicated to machine learning. The toolbox provides a large set of state of the art algorithms. Using the same API, it is easy to develop its own processing chain, including model selection, learning, prediction and accuracy assessment.\n",
    "\n",
    "This notebook can be run on Colab: [here](https://colab.research.google.com/github/DataScience4Geoscience/Toulouse2020/blob/master/Notebooks/Introduction_to_Python/N3_Introduction_to_scikit-learn.ipynb).\n",
    "\n",
    "The following example is taken from [http://scikit-learn.org/stable/tutorial/statistical_inference/index.html]\n",
    "\n",
    "## Loading data\n",
    "Several conventional data set are included in the toolbox. It is off course possible to use its own data: it should be represented by a 2D Scipy Array. The first axis (lines) is the samples and the second axis is the features.\n",
    "\n",
    "Let start with the well known *Iris* data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "data = iris.data\n",
    "data.shape\n",
    "iris.target.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 150 samples with 4 features. We can plot the data for some pairs of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "f,((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2,figsize=(16, 12))\n",
    "# Axe 1 and 2\n",
    "ax1.scatter(data[:,0], data[:,1],c=iris.target,)\n",
    "ax1.set_xlabel(iris.feature_names[0])\n",
    "ax1.set_ylabel(iris.feature_names[1])\n",
    "\n",
    "# Axe 1 and 3\n",
    "ax2.scatter(data[:,0], data[:,2],c=iris.target,)\n",
    "ax2.set_xlabel(iris.feature_names[0])\n",
    "ax2.set_ylabel(iris.feature_names[2])\n",
    "\n",
    "# Axe 2 and 4\n",
    "ax3.scatter(data[:,1], data[:,3],c=iris.target,)\n",
    "ax3.set_xlabel(iris.feature_names[1])\n",
    "ax3.set_ylabel(iris.feature_names[3])\n",
    "\n",
    "# Axe 3 and 4\n",
    "ax4.scatter(data[:,2], data[:,3],c=iris.target,)\n",
    "ax4.set_xlabel(iris.feature_names[2])\n",
    "ax4.set_ylabel(iris.feature_names[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Supervised learning\n",
    "The problem is to learn a function linking the observation (here *data*) and the external data (here *target*). With scikit-learn, we need to select one alorithm then apply the *fit* method and the *predict* method. Using a K-Nearest Neighbors classifiers, it reduces to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier() # Creation of the classifier\n",
    "knn.fit(iris.data, iris.target) # Model fitting\n",
    "y_predict = knn.predict(iris.data) # Prediction\n",
    "\n",
    "print(y_predict[::10])\n",
    "print(iris.target[::10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, easy. But in practice we never do that: we should fit and predict with different samples. We will see later that it leads to a biased estimation of the true error rate of our algorithm. We need to split the data set into a training set and a validation set. Hopefully, scikit-learn provides a set of tools to manipulate the data. Furthermore, since the *fit* and the *predict* function are always the same whatever the algorithm, benchmarking using scikit-learn is super easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model, svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy as sp\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Init classifier\n",
    "classifiers = [linear_model.LogisticRegression(),svm.SVC(kernel='linear'), KNeighborsClassifier()]\n",
    "names = [\"Logistic Regression\", \"Support Vector Machines\", \"K Nearest Neighbors\"]\n",
    "\n",
    "# Split data -> 2/3 for learning & 1/3 for validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.75, random_state=0)\n",
    "\n",
    "for clf,name in zip(classifiers,names):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test) # predict the label of X_test from X_train and y_train\n",
    "    error = accuracy_score(y_test, y_pred) # Compute the overall accuracy\n",
    "    print('Errors for {1}: \\t {0:.2f}'.format(error,name)) # \\t means \"tabular\" space, and {0:.2f} \n",
    "                                                           # means we print only two first decimal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model complexity\n",
    "Each algorithm has a set of hyperparameters that needs to be optimized for the considered data set. This issue will be addressed later. Here, we just illustrate the fact that they could have a great influence on the final decision.\n",
    "\n",
    "For the KNN, the number of neighors considered for the decision is the main hyperparemeter to set-up for small to medium size problem. Default value for scikit-learn is set to 5 (do knn? for help). In the following we are going to plot the overall accuracy function of the hyperparemeter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = sp.arange(1,25)\n",
    "errors_train, errors_validation = [], []\n",
    "for n_ in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_)\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = knn.predict(X_train)\n",
    "    errors_train.append(accuracy_score(y_train, y_pred))\n",
    "    \n",
    "    y_pred = knn.predict(X_test)\n",
    "    errors_validation.append(accuracy_score(y_test, y_pred))\n",
    "    \n",
    "plt.plot(neighbors,errors_train)\n",
    "plt.plot(neighbors,errors_validation)\n",
    "plt.legend([\"Train\", \"Test\"])\n",
    "plt.xlabel(\"Number of neighbors\")\n",
    "plt.ylabel(\"Overall accuracy\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
