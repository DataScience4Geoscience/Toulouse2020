{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSG 2020: Regression methods (practice)\n",
    "\n",
    "## Pierre Tandeo, IMT-Atlantique (pierre.tandeo@imt-atlantique.fr)\n",
    "\n",
    "In this notebook, we apply different regression methods to a real geophysical problem: the Lorenz-63 system. This system is said to be chaotic, meaning that its evolution is highly depending on the initial condition. Consequently, the evolution of this system is hard to predict.\n",
    "\n",
    "![L63](https://upload.wikimedia.org/wikipedia/commons/1/13/A_Trajectory_Through_Phase_Space_in_a_Lorenz_Attractor.gif \"Lorenz-63\")\n",
    "\n",
    "Here, based on a set of observations, the goal is firstly to identify the Lorenz-63 system, meaning that we want to retrieve the equations of the system using learning tools. The second objective is, from the identified data-driven models, to generate artificial trajectories of the Lorenz-63 system.\n",
    "\n",
    "This practice is largely inspired by this article: https://www.pnas.org/content/pnas/113/15/3932.full.pdf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import library and adjust python parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import classical libraries\n",
    "%matplotlib inline\n",
    "%pylab inline\n",
    "\n",
    "# avoid warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# figure size\n",
    "rcParams['figure.figsize'] = (16, 9)\n",
    "\n",
    "# print only 2 decimals\n",
    "set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data generation\n",
    "\n",
    "We generate data following the 3-dimensional Lorenz-63 system, also called the strange attractor, given by:\n",
    "\n",
    "${\\displaystyle {\\begin{aligned}{\\frac {\\mathrm {d} x_1}{\\mathrm {d} t}}&=\\sigma (x_2-x_1),\\\\[6pt]{\\frac {\\mathrm {d} x_2}{\\mathrm {d} t}}&=x_1(\\rho -x_3)-x_2,\\\\[6pt]{\\frac {\\mathrm {d} x_3}{\\mathrm {d} t}}&=x_1 x_2-\\beta x_3,\\end{aligned}}}$\n",
    "\n",
    "where the physical parameters are $\\left(\\sigma=10, \\rho=28, \\beta=8/3\\right)$. We use Runge-Kutta 4-5 to integrate the model, using the *odeint()* Python function. The integration time is $\\mathrm{d}t=0.001$ and we generate a sequence of $T=100$ Lorenz times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lorenz-63 dynamical model\n",
    "def Lorenz_63(x, dx, sigma, rho, beta):\n",
    "    dx = zeros((3))\n",
    "    dx[0] = sigma*(x[1]-x[0])\n",
    "    dx[1] = x[0]*(rho-x[2])-x[1]\n",
    "    dx[2] = x[0]*x[1] - beta*x[2]\n",
    "    return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.integrate import odeint\n",
    "\n",
    "# define the parameters\n",
    "x0 = array([8,0,30]) # initial condition\n",
    "dt = 0.001 # integration time step\n",
    "T = 100 # number of Lorenz-63 times\n",
    "sigma = 10\n",
    "rho = 28\n",
    "beta = 8/3\n",
    "\n",
    "# generate the Lorenz-63 system\n",
    "x = odeint(Lorenz_63, x0, arange(0.01,T,dt), args=(sigma, rho, beta))\n",
    "time = arange(0.01, T, dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize data\n",
    "\n",
    "They are 2 ways of visualizing the Lorenz-63 system. The first is to consider the system as a 3-dimensional time series: we plot each variable as a function of time. The second is the phase-space representation where we plot the relationships between variables in 3D and we track the trajectory along time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# time series representation\n",
    "plot(time, x)\n",
    "xlabel('Lorenz-63 time', size=20)\n",
    "legend(['x_1','x_2','x_3'], prop={'size': 20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# phase-space representation\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.plot(x[:,0], x[:,1], x[:,2], 'k')\n",
    "ax.set_xlabel('$x_1$', size=20);ax.set_ylabel('$x_2$', size=20);ax.set_zlabel('$x_3$', size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the training and validation datasets\n",
    "\n",
    "Here, we want to statistically emulate the Lorenz-63 system, using a regression formulation such that $Y=f(X)$. The Lorenz-63 system is an Ordinary Differential Equation (ODE), where from an initial information at time $t$, the ODE results correspond to increments of each component of the system between $t$ and $t+\\mathrm{d}t$.\n",
    "\n",
    "**Questions:**\n",
    "- construct the output $Y$ corresponding to the ODE formulation of the Lorenz-63\n",
    "- construct the input $X$ with the information of the Lorenz-63 at time $t$ (we suggest to take the 3 dimensions and their products)\n",
    "- create the training dataset noted (*X_train*, *Y_train*) corresponding to the first 2/3 of time series\n",
    "- create the validation dataset noted (*X_test*, *Y_test*) corresponding to the last part of the time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy.random import normal\n",
    "\n",
    "# output Y\n",
    "Y = (x[1:,]-x[:-1,:])/dt\n",
    "\n",
    "# input X    \n",
    "X = vstack((x[:-1,0], x[:-1,1], x[:-1,2],\\\n",
    "            x[:-1,0]*x[:-1,0], x[:-1,0]*x[:-1,1], x[:-1,0]*x[:-1,2],\\\n",
    "            x[:-1,1]*x[:-1,1], x[:-1,1]*x[:-1,2], x[:-1,2]*x[:-1,2]\\\n",
    "           )).transpose()\n",
    "\n",
    "# training set\n",
    "T_train = int(T/dt*2/3) # size of the training set\n",
    "X_train = X[0:T_train,:]\n",
    "Y_train = Y[0:T_train,:]\n",
    "\n",
    "# add noise to training data\n",
    "#X_train = X_train + random.normal(0, 0.5, shape(X_train))\n",
    "#Y_train = Y_train + random.normal(0, 0.5, shape(Y_train))\n",
    "\n",
    "# validation set\n",
    "X_test = X[T_train+1:,:]\n",
    "Y_test = Y[T_train+1:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the multiple linear regression\n",
    "\n",
    "The regression $Y=f(X)$ can be simply written as a global linear regression without intercept such that: \n",
    "\\begin{equation}\n",
    "Y=\\sum_{i=1}^p \\beta_i X_i.\n",
    "\\end{equation}\n",
    "\n",
    "**Questions:**\n",
    "- estimate the $(\\beta_1, \\dots, \\beta_p)$ using the ordinary least squares\n",
    "- compare the estimated parameters to the true ones\n",
    "- from the initial values in *X_test*, generate the predicted trajectories using the linear regressions and compare them to the true ones of *Y_test*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import functions\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# adjust multiple linear regression (mlr) between X and Y\n",
    "reg_mlr = LinearRegression(fit_intercept=False)\n",
    "reg_mlr.fit(X_train, Y_train)\n",
    "\n",
    "# print the estimated parameters\n",
    "print('Estimated parameters for x_1: ' + str(around(reg_mlr.coef_[0,:], 1)))\n",
    "print('Estimated parameters for x_2: ' + str(around(reg_mlr.coef_[1,:], 1)))\n",
    "print('Estimated parameters for x_3: ' + str(around(reg_mlr.coef_[2,:], 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to transform the input and output of the regression to a L63 coordinate\n",
    "def XY_to_L63(X, Y, dt):\n",
    "    \n",
    "    L63 = Y*dt + X\n",
    "    \n",
    "    # return the L63 coordinate\n",
    "    return L63\n",
    "\n",
    "# function to transform a L3 coordinate to the input of the regression, assuming that:\n",
    "# X = [x1, x2, x3, x1x1, x1x2, x1x3, x2x2, x2x3, x3x3]\n",
    "def L63_to_X(trajectory):\n",
    "    \n",
    "    X = vstack((trajectory[0], trajectory[1], trajectory[2],\\\n",
    "        trajectory[0]*trajectory[0], trajectory[0]*trajectory[1], trajectory[0]*trajectory[2],\\\n",
    "        trajectory[1]*trajectory[1], trajectory[1]*trajectory[2], trajectory[2]*trajectory[2]\\\n",
    "        )).transpose()\n",
    "    \n",
    "    # return the X vector\n",
    "    return X\n",
    "\n",
    "# apply the linear regressions (only the firt time step is kept into account)\n",
    "Y_mlr = reg_mlr.predict(X_test)\n",
    "\n",
    "# apply sequentially the linear regressions from the initial value of X_test\n",
    "traj_true = Y_test*0\n",
    "traj_mlr = Y_test*0\n",
    "traj_true[0,:] = XY_to_L63(X_test[0,0:3], Y_test[0,:], dt)\n",
    "traj_mlr[0,:] = XY_to_L63(X_test[0,0:3], Y_mlr[0,:], dt)\n",
    "for t in range(1,len(X_test)):\n",
    "    traj_true[t,:] = XY_to_L63(X_test[t,0:3], Y_test[t,:], dt)\n",
    "    # apply the linear regressions recursively\n",
    "    traj_mlr[t,:] = XY_to_L63(traj_mlr[t-1,:], reg_mlr.predict(L63_to_X(traj_mlr[t-1,:])), dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# time series representation\n",
    "plot(time[T_train+2:], traj_true[:,1], 'r')\n",
    "plot(time[T_train+2:], traj_mlr[:,1], 'k')\n",
    "xlabel('Lorenz-63 time', size=20)\n",
    "ylabel('$x_2$', size=20)\n",
    "legend(['truth','regression'], prop={'size': 20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# phase-space representation\n",
    "fig = figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.plot(traj_true[:,0], traj_true[:,1], traj_true[:,2], 'r')\n",
    "ax.plot(traj_mlr[:,0], traj_mlr[:,1], traj_mlr[:,2], 'k')\n",
    "ax.set_xlabel('$x_1$', size=20);ax.set_ylabel('$x_2$', size=20);ax.set_zlabel('$x_3$', size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Study the sensibility of the regression\n",
    "\n",
    "The current integration time of the Lorenz-63 is too short. Moreover, the training dataset is \"clean\", in a sense that the observations are not noisy. Thus, this regression problem is relatively easy. Here, we suggest to study the sensibility of the regression to key parameters.\n",
    "\n",
    "**Questions:**\n",
    "- reduce the integration time to $\\mathrm{d}t=0.01$, compare the identified models and the generated trajectories\n",
    "- generate a training dataset with an additive Gaussian noise (mean=0, std=0.5), compare the identified models and the generated trajectories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the local linear regression\n",
    "\n",
    "As you have seen previously, the global linear regression can not reproduce realistic trajectories of the L63. We thus suggest to implement the local linear regression to improve the results. The local regressions are build from nearest neighbors. Thus, the size of the training dataset need to be increased."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
