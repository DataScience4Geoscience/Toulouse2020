{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook can be run on colab: [here](https://colab.research.google.com/github/DataScience4Geoscience/Toulouse2020/blob/master/Notebooks/Classification/N1_Classification_LDA_QDA.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification \n",
    "In this notebook, the classification with LDA and QDA is illustrated on the Digits data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.datasets import load_digits\n",
    "# Load digits\n",
    "X, y = load_digits(return_X_y=True)\n",
    "print(X.shape)\n",
    "print(X.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set is made available by NIST to extract normalized bitmaps of handwritten digits from a preprinted form. From a total of 43 people, 30 contributed to the training set and different 13 to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of 4x4 and the number of on pixels are counted in each block. This generates an input matrix of 8x8 where each element is an integer in the range 0..16 (https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits)\n",
    "\n",
    "We can visualize the data by reshaping correctly each sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the first element\n",
    "plt.figure()\n",
    "plt.imshow(X[0,:].reshape(8,8),cmap=\"gray\")\n",
    "plt.title(\"Label = {}\".format(y[0]))\n",
    "\n",
    "# Plot the hundredth element\n",
    "plt.figure()\n",
    "plt.imshow(X[100,:].reshape(8,8),cmap=\"gray\")\n",
    "plt.title(\"Label = {}\".format(y[100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform the classification and the validation of the model, we should split our data sets into two disjoint parts. The classification accuracy is assessed using the global accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA,\\\n",
    "                                        QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score as OA\n",
    "\n",
    "# Split the data -> train_size=0.20 means we keep 20% of the data for training and 80% for validation\n",
    "# The stratification ensures that the proportion of each class from the orginal data is preserved in the train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.3, random_state=0, stratify=y)\n",
    "\n",
    "MODELS = [LDA(), QDA()]\n",
    "oa = []\n",
    "for model in MODELS:\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    oa.append(OA(y_test, y_pred))\n",
    "print(oa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up hyperparameters\n",
    "Both LDA and QDA have hyperparameters, which are related to the estimation of the covariance matrices. They usually have significant influences on the final classification results. \n",
    "\n",
    "For instance, QDA implemented in Sklearn has a regulation parameter that control the condition number of the class covariance matrix: $$(1-\\lambda)\\Sigma + \\lambda\\mathbf{I}.$$ The following code shows the influence of this hyperparameter on the overall accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "reg_param = sp.linspace(0,1)\n",
    "print(reg_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oa = []\n",
    "for reg_param_ in reg_param:\n",
    "    model = QDA(reg_param=reg_param_)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    oa.append(OA(y_test, y_pred))\n",
    "plt.plot(reg_param, oa)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best hyperparameters value: {}\".format(reg_param[sp.argmax(oa)]))\n",
    "print(\"Best classification value: {}\".format(oa[sp.argmax(oa)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
